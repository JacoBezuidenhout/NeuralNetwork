\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@input{title.aux}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Dataset}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{I have used a web scraper to scrape data from 2 websites:}{1}{section*.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Number of chunks used}{1}{section.1.1}}
\@writefile{toc}{\contentsline {paragraph}{I used different size chunks. All were greater than 300 characters. }{1}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Afrikaans:}{1}{subsection.1.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}English:}{1}{subsection.1.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}How frequencies were calculated}{1}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}How special characters were handled}{2}{section.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Store format}{2}{section.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}How the data was pre-processed}{2}{section.1.5}}
